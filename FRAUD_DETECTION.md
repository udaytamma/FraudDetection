# Fraud Detection Platform - Project Reference

> This document is the single source of truth for the Fraud Detection Platform project. Claude Code should read this file when working on fraud detection implementation.

## Project Overview

**Purpose:** Real-time fraud detection system for payment transactions, designed for interview preparation (Principal TPM/Senior TPM at Mag7 companies) and potential implementation.

**Status:** Design Complete, Implementation Pending

**Location:** `/Users/omega/Projects/FraudDetection`

---

## Key Files

| File | Purpose |
|------|---------|
| `PRDs/Master Prompt - Fraud Detection.txt` | **PRIMARY REFERENCE** - The master prompt that defines all design constraints, practitioner requirements, and system architecture |
| `PRDs/Fraud-Detection-PRD - Perplexity.md` | PRD generated by Perplexity |
| `PRDs/Fraud_Detection_PRD_v1.2 - Opus.docx` | PRD generated by Claude Opus |
| `PRDs/Capstone - Fraud Detection - PRD-Gemini.pdf` | PRD generated by Gemini |

---

## Master Prompt Summary

The master prompt (`PRDs/Master Prompt - Fraud Detection.txt`) establishes:

### 10 Practitioner Constraints

1. **Net Revenue Optimization** - Maximize revenue minus fraud losses, not just minimize fraud
2. **Policy > ML** - Business controls decisions without engineering deploys
3. **Fraud Taxonomy** - Criminal, friendly, and merchant error need different responses
4. **Evidence as Revenue** - Disputes are winnable with proper evidence
5. **Velocity > Sophistication** - Attacks cause damage in minutes, not days
6. **Adversarial Resilience** - Fraudsters probe and adapt to thresholds
7. **Economic Optimization** - Thresholds need data-driven tuning
8. **Model Lifecycle** - Production ML needs rollback and monitoring
9. **PCI/PII Governance** - Compliance boundaries shape architecture
10. **Multi-Signal Integration** - Future phases need telco/MSP signals

### Non-Negotiable Numbers

- **<200ms** end-to-end latency for online decisioning
- **Exactly-once** business effects (no duplicate charges or blocks)
- **>92%** approval rate target
- **<10%** false positive rate among blocks

---

## Technology Stack (Selected)

| Component | Technology | Why Selected |
|-----------|------------|--------------|
| Event Streaming | Kafka | Exactly-once semantics, partition-by-key ordering, log retention for replay |
| Stream Processing | Flink | True event-by-event processing, native sliding windows, checkpoint recovery |
| Fast State Store | Redis Cluster | <5ms reads, ZSET for sliding windows, HyperLogLog for distinct counts |
| Feature Store | Feast + Delta Lake | Open source, Spark integration, point-in-time correctness |
| Policy Engine | OPA + Custom Wrapper | Hot-reloadable Rego policies, version-controlled, audit trail |
| Model Serving | Seldon | Kubernetes-native, canary deployments, explainability |
| Evidence Store | PostgreSQL + S3 | Structured queries for disputes, cheap blob storage for documents |
| Monitoring | Prometheus + Grafana | Standard stack, PromQL flexibility, alerting |

---

## Architecture Overview

```
                    ┌─────────────────────────────────────────────────────────┐
                    │                    KAFKA CLUSTER                         │
                    │  payment-events → fraud-decisions → evidence-requests   │
                    └─────────────────────────────────────────────────────────┘
                              │                    ▲
                              ▼                    │
┌──────────────┐    ┌─────────────────┐    ┌─────────────────┐    ┌──────────────┐
│   INGESTION  │───▶│  FLINK CLUSTER  │───▶│  DECISION SVC   │───▶│  EVIDENCE    │
│   GATEWAY    │    │  (Features)      │    │  (Policy+ML)    │    │  VAULT       │
└──────────────┘    └─────────────────┘    └─────────────────┘    └──────────────┘
                              │                    │
                              ▼                    ▼
                    ┌─────────────────┐    ┌─────────────────┐
                    │  REDIS CLUSTER  │    │  MODEL SERVICE  │
                    │  (Real-time)    │    │  (Seldon)       │
                    └─────────────────┘    └─────────────────┘
                              │
                              ▼
                    ┌─────────────────┐
                    │  FEATURE STORE  │
                    │  (Feast+Delta)  │
                    └─────────────────┘
```

---

## Data Model

### Core Entities (Derived from Money Flow)

| Entity | Fraud Vector | Storage | Key Fields |
|--------|--------------|---------|------------|
| **Card** | Stolen, enumerated, tested | Redis Hash | first_seen, chargeback_count, distinct_merchants_30d |
| **Device** | Shared across fraud rings, emulated | Redis Hash | distinct_cards_24h (HLL), is_emulator, is_rooted |
| **IP** | Proxied, VPN, datacenter | Redis Hash | distinct_cards_1h, is_datacenter, geo_country |
| **User** | Fake accounts, ATO, friendly fraud | Redis Hash | account_age_days, chargeback_rate_90d, risk_tier |
| **Merchant** | Collusion, high-risk MCC | Redis Hash | mcc, chargeback_rate, is_high_risk |

### Event Types

| Event | State Change | Latency Requirement |
|-------|--------------|---------------------|
| Authorization | Transaction created | <200ms decision |
| Capture | Money moves | Async |
| Refund | Reversal | Async |
| Chargeback | Loss recorded | Batch |
| Dispute Outcome | ML training label | Batch |

### Feature Categories

| Category | Computation | Storage | Example |
|----------|-------------|---------|---------|
| Velocity (real-time) | Sliding window counters | Redis ZSET | card_attempts_10m |
| Aggregates (near real-time) | Incremental updates | Redis Hash | user_chargeback_count |
| Historical (batch) | Daily rollups | Feast | user_chargeback_rate_90d |

---

## Decision Logic

### Rule Hierarchy (Priority Order)

1. **Hard Overrides** - Blocklists/allowlists (immediate)
2. **Velocity Circuit Breakers** - Card testing, enumeration
3. **ML Score Thresholds** - Criminal fraud, friendly fraud
4. **Contextual Rules** - High value + new user, geo mismatch
5. **Default Decision** - ALLOW

### Decision Space

| Decision | Business Meaning | Trade-off |
|----------|------------------|-----------|
| ALLOW | Proceed | Revenue captured, fraud risk accepted |
| FRICTION | Request verification (3DS, OTP) | Some abandonment, reduced fraud |
| REVIEW | Hold for analyst | Delay, human cost, higher accuracy |
| BLOCK | Decline | Zero fraud risk, lost revenue if legitimate |

### Profit-Based Thresholds

```
Expected Loss = P(fraud) × (amount + chargeback_fee + penalty + ops_cost)
Expected Gain = P(legitimate) × (revenue from transaction)

If Expected Loss > Expected Gain × risk_tolerance → BLOCK or FRICTION
Else → ALLOW
```

---

## Failure Modes & Fallbacks

| Component | Failure Mode | Fallback |
|-----------|--------------|----------|
| Redis | Node down | Replica failover, then default features |
| Redis Cluster | Multiple nodes down | Safe mode activation |
| ML Service | Timeout/crash | Rule-based scoring |
| Policy Engine | Config error | Hardcoded safe mode rules |
| Evidence Vault | Write failure | Queue locally, retry |

### Safe Mode Behavior

- Blocklist checks still work (local cache)
- Rule-based scoring replaces ML
- Default action is FRICTION, not ALLOW
- Lower thresholds (more conservative)

### Attack vs Bug Detection

| Signal | Attack | Bug |
|--------|--------|-----|
| Block rate spike | Concentrated on few entities | Spread across all traffic |
| Geographic pattern | Single region | Global |
| User complaints | None | Support tickets spike |
| Time pattern | Sustained | Correlates with deployment |

---

## Testing Strategy

### Testing Pyramid

1. **Unit Tests** - Decision logic, edge cases (seconds)
2. **Integration Tests** - End-to-end flows, idempotency (minutes)
3. **Chaos Tests** - Failure resilience (minutes)
4. **Replay Tests** - Historical accuracy (hours) **← Most Critical**
5. **Load Tests** - Capacity at 2x traffic (hours)

### Historical Replay Testing

- Replay 30 days of transactions through new pipeline
- Get features **as they were at transaction time** (not current)
- Compare decisions to actual fraud outcomes
- Measure: approval rate delta, fraud detection rate, false positive rate

### Go/No-Go Criteria

| Category | Metric | Target | Max Allowed |
|----------|--------|--------|-------------|
| Performance | E2E P99 latency | 150ms | 200ms |
| Performance | Error rate | 0.1% | 1% |
| Accuracy | Approval rate delta | 0% | -2% |
| Accuracy | Fraud detection delta | 0% | -5% |
| Accuracy | False positive delta | 0% | +1% |

---

## Phase Plan

### Phase 1 (Sprint 1-2): Core Pipeline

- Real-time transaction decisioning (<200ms)
- Velocity features (card, device, IP, user)
- Criminal fraud detection
- Policy engine with configurable thresholds
- Evidence vault
- Basic monitoring

### Phase 2 (Sprint 3-4): Optimization

- Automated representment
- Economic optimization UI
- Champion/challenger A/B testing
- Model retraining pipeline

### Phase 3: Extended Detection

- IRSF detection (telco signals)
- ATO detection (session/login data)
- Subscription fraud

---

## Nebula Documentation

Interview preparation materials in ProjectDocs:

**Location:** `/Users/omega/Projects/ProjectDocs/src/pages/nebula/fraud-detection-thinking/`

**Pages:**
- `index.tsx` - Overview
- `constraints.tsx` - Section 1: Constraints First
- `scope.tsx` - Section 2: Scope Definition
- `technology.tsx` - Section 3: Technology Selection (CREST Framework)
- `data-model.tsx` - Section 4: Data Model (8-step derivation)
- `logic-policy.tsx` - Section 5: Logic & Policy (7-step derivation)
- `failure-modes.tsx` - Section 6: Failure Modes (7-step derivation)
- `testing.tsx` - Section 7: Testing & Validation (7-step derivation)
- `checklist.tsx` - Section 8: Pre-Production Checklist

**Each section contains:**
1. Thinking Process - Systematic step-by-step derivation
2. Decision Context - Specific choices and rationale
3. Derivation Path - Visual flow of how to arrive at design
4. Interview Application - 2-minute response template

---

## Key Design Principles

1. **Constraints before solutions** - Enumerate non-negotiables first
2. **Design for the whole, build in phases** - Don't solve tomorrow's problem, but don't block it
3. **ML informs, Policy decides** - Separation is non-negotiable
4. **Everything fails** - Design for when, not if
5. **Profit-based thresholds** - Expected value, not fixed cutoffs
6. **Prepare at architect depth, deliver at principal depth** - Adjust based on interviewer cues

---

## CREST Framework (Technology Selection)

| Letter | Meaning | What You Demonstrate |
|--------|---------|---------------------|
| C | Constraints | Start with requirements, not solutions |
| R | Risks & Trade-offs | Understand nothing is free |
| E | Evaluation | Compared alternatives systematically |
| S | Selection | Made a defensible choice |
| T | Testing/Validation | Know how to verify the choice works |

---

## Quick Reference

**Master Prompt:** `/Users/omega/Projects/FraudDetection/PRDs/Master Prompt - Fraud Detection.txt`

**Nebula Pages:** `/Users/omega/Projects/ProjectDocs/src/pages/nebula/fraud-detection-thinking/`

**ProjectDocs (Functional Docs):** `/Users/omega/Projects/ProjectDocs/docs/fraud-platform/`

---

*Last Updated: 2026-01-03*
